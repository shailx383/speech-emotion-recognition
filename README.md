# Speech Emotion Recognition

- Dataset used: [RAVDESS](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)
- 3 notebooks:
    - [Data Analysis, Model 1: CNN (1-channel), Mel-spectrogram](https://github.com/shailx383/speech-emotion-recognition/blob/main/EDA_and_model1.ipynb)
    - [Model 2: CNN (1-channel), MFCCs](https://github.com/shailx383/speech-emotion-recognition/blob/main/model2.ipynb)
    - [Model 3: 2D-CNN (3-channel), Stacked audio features](https://github.com/shailx383/speech-emotion-recognition/blob/main/model3.ipynb)
- [Dependencies file](https://github.com/shailx383/speech-emotion-recognition/blob/main/requirements.txt)
